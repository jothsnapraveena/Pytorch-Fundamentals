{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch importing & version checking"
      ],
      "metadata": {
        "id": "53V73VrdhWX1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B8h7kquAdC3h"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LD372puBgmWl",
        "outputId": "df25a0f1-1de5-4950-9804-84bd3f1190d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTaw33WqgsdE",
        "outputId": "150773ce-171c-432b-924a-7fad005dc251"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Tensors"
      ],
      "metadata": {
        "id": "P6HEvImBhxnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0d=torch.tensor(1)  # creates a zero-dimensional tensor\n",
        "tensor1d=torch.tensor([1,2,3])  # creates a one-dimensional tensor\n",
        "tensor2d=torch.tensor([[1,2],[3,4]])  # creates a two-dimensional tensor\n",
        "tensor3d=torch.tensor([[[1,2],[3,4]], # creates a three-dimensional tensor\n",
        "                      [[5,6],[7,8]]])\n",
        "\n"
      ],
      "metadata": {
        "id": "sQPqE8gwhT1U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor data types"
      ],
      "metadata": {
        "id": "YTgivtOejML3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor0d.dtype) # pytorch adopts the default 64-bit integer data type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o87PEOPHjCvv",
        "outputId": "0003b7c2-bf41-4588-bcbc-3ee418e5ef79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1dvec=torch.tensor([1.0,2.0,3.0]) ## pytorch adopts the default 32-bit precision if we create tensors from python floats\n",
        "print(tensor1dvec.dtype)\n",
        "\n",
        "## This choice is primarily due to the balance between precision and computational efficiency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVBw2ehDjV6S",
        "outputId": "4627f257-84b7-4d29-cd62-1493a9d81796"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moreover it is possible to chnage the precision using a tensor's .to method**"
      ],
      "metadata": {
        "id": "rffCMP_zlk8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "floatvec=tensor1d.to(torch.float32)\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9_97QUXjvdL",
        "outputId": "3ad6a721-4a69-4588-de33-d9985747f91e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**common PyTorch tensor operation**"
      ],
      "metadata": {
        "id": "XTqeRRZYl9FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d=torch.tensor([[1,2,3],[4,5,6]])"
      ],
      "metadata": {
        "id": "SJ8V_axXmEYD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YPkggqnmSmw",
        "outputId": "c3f537ea-e16b-41dc-fe92-3beb299699a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To reshape the tensor to 3*2 tensor , we can use .reshape method**"
      ],
      "metadata": {
        "id": "nnocsdkVm58a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.reshape(3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wZJTsPZmaOv",
        "outputId": "f8e306a2-793f-4546-e208-3993e9edf45d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**However to reshae the tensor there is one more command .view**"
      ],
      "metadata": {
        "id": "L74udjocnPuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.view(3,2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5DZIA4vmfFk",
        "outputId": "e8bf0342-343a-4e3e-9147-69f31c6910c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transpose using .T**"
      ],
      "metadata": {
        "id": "P9hQWEVZoFAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTQ3s-eKnNA_",
        "outputId": "70b3a4b5-960b-42eb-fdff-3ddf80fb80d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensor multiplication**"
      ],
      "metadata": {
        "id": "oT64vRUtojfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d.matmul(tensor2d.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIhDO6cXoSdr",
        "outputId": "e7b06f76-6726-4c50-d446-8e9c9f5bd031"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14, 32],\n",
            "        [32, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we can also adopt the @ operator**"
      ],
      "metadata": {
        "id": "nD-I3KTFoqVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d@tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwA_0RxXooGw",
        "outputId": "de69889f-6bae-48ed-ffba-795bccc5b58b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[14, 32],\n",
            "        [32, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computational Graph\n",
        "- **PyTorch also known as autograd which is automatic differentiation engine**\n",
        "- **A  computational graph is a directed graph that allows us to express and visualize mathematical expressions**"
      ],
      "metadata": {
        "id": "esthivcdo8U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A logistic regression forward pass"
      ],
      "metadata": {
        "id": "3WTf9Dp0puDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F # This import statement is a common convention in PyTorch to prevent long lines of code\n",
        "y=torch.tensor([1.0]) # True Label\n",
        "x1=torch.tensor([1.1]) # Input feature\n",
        "w1=torch.tensor([2.2]) #Weight paramter\n",
        "b=torch.tensor([0.0])  # Bias Unit\n",
        "z=x1*w1+b #Net input\n",
        "a=torch.sigmoid(z) #activation and output\n",
        "loss=F.binary_cross_entropy(a,y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCqTepdao1ey",
        "outputId": "906277e7-22ab-44a3-b0d8-adcfa28432b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch builds computational graph in the background , and we can use this to calculate gradients of a loss function with respect to model parameters (here w1,b) to train the models**"
      ],
      "metadata": {
        "id": "fjuyMwkEsMaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "y=torch.tensor([1.0]) # True Label\n",
        "x1=torch.tensor([1.1]) # Input feature\n",
        "w1=torch.tensor([2.2],requires_grad=True) #Weight paramter\n",
        "b=torch.tensor([0.0],requires_grad=True)  # Bias Unit\n",
        "z=x1*w1+b #Net input\n",
        "a=torch.sigmoid(z) #activation and output\n",
        "loss=F.binary_cross_entropy(a,y)\n",
        "grad_l_w1=grad(loss,w1,retain_graph=True)\n",
        "grad_l_b=grad(loss,b,retain_graph=True)\n",
        "print(grad_l_w1)\n",
        "print(grad_l_b)\n"
      ],
      "metadata": {
        "id": "d39YuOSSsnQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737d6bbe-5d73-4dbf-f0c4-7d815887baec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**another automated way to get gradients**"
      ],
      "metadata": {
        "id": "sRlWk1F8yipu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHzyZwdfySsg",
        "outputId": "e2d4a045-4bb0-4591-aff3-adc87a8c9786"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Multilayer neural networks"
      ],
      "metadata": {
        "id": "qwRe2iPlyrvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **When implementing a neural network in PyTorch , we can subclass the torch.nn.Module class to define our own custon network architecture**\n",
        "- **Within this sublass, we define the network layers in the __init__ constructir and specify how the layers interact in the forward method**"
      ],
      "metadata": {
        "id": "hHlW0wtdzJDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilayer perceptron with two hidden layers"
      ],
      "metadata": {
        "id": "_lUmBap6z3GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):   # coding the number of inputs and outputs as variables allows us to reuse the same code for datasets with different numbers of features and classes\n",
        "  def __init__(self,num_inputs,num_outputs):\n",
        "    super().__init__()\n",
        "    self.layers=torch.nn.Sequential(\n",
        "        #first hidden layer\n",
        "        torch.nn.Linear(num_inputs,30), # The Linear Layer takes the number of input and output nodes as arguments\n",
        "        torch.nn.ReLU(),  # Non linear activation functions are placed between the hidden layers\n",
        "        # second hidden layer\n",
        "        torch.nn.Linear(30,20), # the number of output nodes of one layer has to match the number of inputs of the next layer\n",
        "        torch.nn.ReLU(),\n",
        "        #output layer\n",
        "        torch.nn.Linear(20,num_outputs),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    logits=self.layers(x)  # The outputs of the last layer are called logits\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "IEw99RVyy5fs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=NeuralNetwork(50,3)"
      ],
      "metadata": {
        "id": "tedVtmSQ2jPG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k5ube8c2x5i",
        "outputId": "e2557b9e-1795-4f29-ea3b-9f6764f6a028"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **The sequentical class makes our life easier if we have series of layers to execute in a specific order**\n"
      ],
      "metadata": {
        "id": "cM5RFGek27rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_params=sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"The total number of trainable model parameters:\",num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS1w33Zq3PEO",
        "outputId": "541b99aa-7f13-4a1c-b348-b2484c874e16"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of trainable model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **For each parameter whoch requires_grad=True counts as a trainable parameter**\n",
        "- **In the case of our neural netwrork model with the preceding two hidden layers, these trainable parameters are contained in torch.nn.Linear layers. A linear layer multiplies the weight matrix and adds a bias vector. This is sometimes referred to as a *feedforward* or fully connected layer**"
      ],
      "metadata": {
        "id": "n5zZ0c3x3yxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEj2dFQc3u8y",
        "outputId": "913e3e52-a1c8-479d-ca48-e4dac2581328"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0298, -0.0778,  0.0777,  ..., -0.0287,  0.0443,  0.0369],\n",
            "        [ 0.1116, -0.1088,  0.0920,  ...,  0.0024,  0.0763, -0.0471],\n",
            "        [ 0.1391, -0.1166,  0.1143,  ...,  0.1185, -0.0386,  0.1252],\n",
            "        ...,\n",
            "        [ 0.1286,  0.1003,  0.0460,  ...,  0.0189, -0.0264, -0.0798],\n",
            "        [-0.1259, -0.1143, -0.0968,  ..., -0.1045, -0.1215,  0.0523],\n",
            "        [-0.0150,  0.1344,  0.0165,  ..., -0.0302, -0.1395,  0.0287]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXoSus-n5DGm",
        "outputId": "1e7bef56-7541-4ec1-bdf6-6f0bdebdf344"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The default setting in torch.nn.Linear is requires_grad=True**"
      ],
      "metadata": {
        "id": "tvaZW8CI6OgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "X=torch.rand((1,50))\n",
        "out=model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdTTIFp85KN3",
        "outputId": "fc043c93-dd16-4eeb-fde5-e211546cafc5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0425, -0.2723,  0.0181]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **In the preceding code, we generated a single random training example x as a toy input and fed it to the model, returning three scores. When we call model(X), it will automatically execute the forward pass of the model.**\n",
        "- **The forward pass refers to calculating output tensors from input tensors. This involves passing the input data through all the neural network layers, starting from input layer, through hidden layers, and finally to the output layer.**\n",
        "-**Output tensor also includes a grad_fn value <AddmmBackward0>.In Addmm operation, Addmm stands for matrixmultplication(mm) followed by an addition(Add).**\n",
        "- **If we want to use network for just predictions without training or backpropagation then it is best practice to use torch.no_grad() context manager. This tells PyTorch no need to keep track of gradients which can result in significant savings in memory and computation**"
      ],
      "metadata": {
        "id": "7M33tMHP8HWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out=model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPGc1Var8qgg",
        "outputId": "9b86da03-fbc7-4d9c-eee6-54d2328a6818"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0425, -0.2723,  0.0181]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **In PyTorch, they return outputs of last layer without passing them to nonlinear activation function**\n",
        "- **To compute class membership probabilities , we haveto call the softmax function (Sigmoid for binary class)**"
      ],
      "metadata": {
        "id": "1ZT5LIHs_LW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out=torch.softmax(model(X),dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4r-k8x4-6qb",
        "outputId": "e420c154-a42f-4503-f6ae-1ea5bd9b8ddc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3500, 0.2782, 0.3719]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **The values can now be interpreted as class-membership probabilities that sum upto 1. The values are roughly equal for this random input, which is expected for a randomly initialized model without training.**"
      ],
      "metadata": {
        "id": "JFqyxCY1AEnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loaders"
      ],
      "metadata": {
        "id": "plTdV5MmAoIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **PyTorch implements Dataset and DataLoader class.The Dataset class is used to instantiate objects that define how each data record is loaded. The DataLoader handles how the data is shuffled and assembled into batches**"
      ],
      "metadata": {
        "id": "br4ai3QxBZq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a small toy dataset\n",
        "X_train=torch.tensor([[-1.2,3.1],\n",
        "                      [-0.9,1.5],\n",
        "                      [-0.3,2.3],\n",
        "                      [2.3,-1.1],\n",
        "                      [2.7,-1.5]\n",
        "                      ])\n",
        "y_train=torch.tensor([0,0,0,1,1])\n",
        "X_test=torch.tensor([\n",
        "    [-0.8,2.1],\n",
        "    [2.6,1.5]\n",
        "])\n",
        "y_test=torch.tensor([0,1])"
      ],
      "metadata": {
        "id": "OJvGFrrgCLiA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining a custom Dataset class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.features=X\n",
        "    self.labels=y\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    one_x=self.features[index]            # Instructions for retrieving exactly one data record and the corresponding label\n",
        "    one_y=self.labels[index]\n",
        "    return one_x,one_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]           # Instructions for returning the total length of the dataset\n",
        "\n",
        "train_ds=ToyDataset(X_train,y_train)\n",
        "test_ds=ToyDataset(X_test,y_test)"
      ],
      "metadata": {
        "id": "aM7VAO2LDQz_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ***The purpose of this ToyDataset class is to instantiate a PyTorch DataLoader**\n",
        "-**__init__ method we set up attributes that we want to access in __getitem__ and __len__ methods.**"
      ],
      "metadata": {
        "id": "_v7rLsCbGMx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Instantiating data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader=DataLoader(\n",
        "  dataset=train_ds,\n",
        "  batch_size=2,              # The ToyDataset instance created earlier serves as input to the dataloader\n",
        "  shuffle=True,\n",
        "  num_workers=0  # The number of background processes\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "  dataset=test_ds,\n",
        "  batch_size=2,\n",
        "  shuffle=False,\n",
        "  num_workers=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "wxlpHkOzGuWR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (X,y) in enumerate(train_loader):\n",
        "  print(F\"Batch {idx+1}:\",X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVo3Se3IIFgF",
        "outputId": "56f5fa18-2479-4147-ea57-513e3d32cfb8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  1.5000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.3000,  2.3000]]) tensor([0, 0])\n",
            "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **From the preceding output teh train_loader iterates over the training dataset, visiting each training example exactly once. This is known as training epoch.**\n",
        "- **As we have 5training examples we got three batches even though we put batch=2 as 5 is not evenly divisible by 2**\n",
        "- **In practice, having a substantially smaller batch as the last batch in a training epoch can disturb the convergence during training. To prevent this, set drop_last=True which will drop the last batch in each epoch**"
      ],
      "metadata": {
        "id": "CGY2sIyIIsUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A training loader that drops the last batch\n",
        "train_loader=DataLoader(\n",
        "  dataset=train_ds,\n",
        "  batch_size=2,              # The ToyDataset instance created earlier serves as input to the dataloader\n",
        "  shuffle=True,\n",
        "  num_workers=0, # The number of background processes\n",
        "  drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "OOw7mCY5JolO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (X,y) in enumerate(train_loader):\n",
        "  print(F\"Batch {idx+1}:\",X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyJp1YF3J-6j",
        "outputId": "f2242512-4009-46c7-ca7a-8895fb3df168"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.3000,  2.3000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  1.5000]]) tensor([1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **num_workers parameter in PyTorch's DataLoader function is crucial for parallelizing data loading and preprocessing**\n",
        "- **when num_workers is set to 0, the data loading will be done in the main process and not in the sepaarte worker processes**\n",
        "- **setting this to 0 for largeer networks lead to significant slowdowns during model training on GPU.**\n"
      ],
      "metadata": {
        "id": "QBYZBA3OL55F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A typical training loop"
      ],
      "metadata": {
        "id": "4gy0VAoOPAre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "torch.manual_seed(123)\n",
        "model=NeuralNetwork(num_inputs=2,num_outputs=2) # The datset has 2 features and 2 clasess\n",
        "optimizer=torch.optim.SGD(\n",
        "  model.parameters(),lr=0.5\n",
        ")\n",
        "num_epochs=3\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx,(features,labels) in enumerate(train_loader):\n",
        "    logits=model(features)\n",
        "    loss=F.cross_entropy(logits,labels)\n",
        "    optimizer.zero_grad()  # sets the gradients from the previous round to 0 to prevent unitended gradient accumulation\n",
        "    loss.backward()\n",
        "    optimizer.step() # The optimizer uses the gradients to update the model parameters\n",
        "    ### LOGGING\n",
        "    print(f\"Epoch:{epoch+1:03d}/{num_epochs:03d}\"\n",
        "          f\" | Batch{batch_idx:03d}/{len(train_loader):03d}\"\n",
        "          f\" | Train Loss:{loss:.2f}\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFHHlSDQMfg0",
        "outputId": "937efb6c-3b3a-43a4-b2c8-31401f91a472"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:001/003 | Batch000/002 | Train Loss:0.78\n",
            "Epoch:001/003 | Batch001/002 | Train Loss:0.63\n",
            "Epoch:002/003 | Batch000/002 | Train Loss:0.49\n",
            "Epoch:002/003 | Batch001/002 | Train Loss:0.27\n",
            "Epoch:003/003 | Batch000/002 | Train Loss:0.04\n",
            "Epoch:003/003 | Batch001/002 | Train Loss:0.01\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=30, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see loss almost reaches 0 after 3 epochs , a sign that the model converged on the training set**."
      ],
      "metadata": {
        "id": "vtIkETJGSwNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_params=sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable model parameters:\",num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6gg9hJVTLW0",
        "outputId": "b4d346ba-3195-4cf1-e5db-8584fa5b3796"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  outputs=model(X_train)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99uYZlkDUQml",
        "outputId": "33086257-73ce-429b-d7c8-e8b0482c3739"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.2642, -4.6650],\n",
            "        [ 1.8481, -2.6799],\n",
            "        [ 2.1177, -3.1727],\n",
            "        [-1.3868,  1.3825],\n",
            "        [-1.6208,  1.6361]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To obtain the class membership probabilities , apply PyTorch's softmax function\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "probas=torch.softmax(outputs,dim=1)\n",
        "print(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bz02JT2Ufij",
        "outputId": "895d2bde-1f94-46cb-f0a6-bd2871f2a5ec"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9996,     0.0004],\n",
            "        [    0.9893,     0.0107],\n",
            "        [    0.9950,     0.0050],\n",
            "        [    0.0590,     0.9410],\n",
            "        [    0.0371,     0.9629]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can convert these value sinto class label predictions uisng PyTorch's argmax function\n",
        "predictions=torch.argmax(probas,dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEL3vi-sU9LR",
        "outputId": "71452727-7702-463c-e20a-6949c5621cc8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction accuracy"
      ],
      "metadata": {
        "id": "PVGDwjdWVpUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import total_ordering\n",
        "def compute_accuracy(model,dataloader):\n",
        "  model=model.eval()\n",
        "  correct=0.0\n",
        "  total_examples=0\n",
        "\n",
        "  for idx,(features,labels) in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      logits=model(features)\n",
        "    predictions=torch.argmax(logits,dim=1)\n",
        "    compare=labels==predictions\n",
        "    correct+=torch.sum(compare)\n",
        "    total_examples+=len(compare)\n",
        "  return (correct/total_examples).item()"
      ],
      "metadata": {
        "id": "j1pcC550VWql"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_accuracy(model,train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjA6jmwQW1XK",
        "outputId": "a6d2ad1e-e418-436f-bb90-35828206912d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_accuracy(model,test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAEDqm2JW5Oo",
        "outputId": "9915cce2-05d7-4281-adfe-49c6da2181cc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and Loading models"
      ],
      "metadata": {
        "id": "ywDSb0sJXF36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model.pth\")"
      ],
      "metadata": {
        "id": "HFNC9I0CXLL2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The model's state_dict is a python dictionary object that maps each layer in the model to its trainable paramters(weights and biases)**"
      ],
      "metadata": {
        "id": "f5tDunpeXbtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=NeuralNetwork(2,2)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYbgPyvAXZm6",
        "outputId": "4ceff5c1-32c9-434b-ac4a-c45960c64097"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RS6SaJOEYd0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}